# ğŸ¦ VPBank AI Credit Score - Infrastructure as Code

> **Háº¡ táº§ng AWS tá»± Ä‘á»™ng hÃ³a cho há»‡ thá»‘ng cháº¥m Ä‘iá»ƒm tÃ­n dá»¥ng thÃ´ng minh sá»­ dá»¥ng AI/ML**

## ğŸ¯ Ã TÆ°á»Ÿng Dá»± Ãn

### Váº¥n Ä‘á»
Há»‡ thá»‘ng cháº¥m Ä‘iá»ƒm tÃ­n dá»¥ng truyá»n thá»‘ng chá»‰ dá»±a vÃ o dá»¯ liá»‡u tÃ i chÃ­nh â†’ **Thiáº¿u chÃ­nh xÃ¡c** cho khÃ¡ch hÃ ng má»›i hoáº·c khÃ´ng cÃ³ lá»‹ch sá»­ tÃ­n dá»¥ng.

### Giáº£i phÃ¡p  
**Há»‡ thá»‘ng AI cháº¥m Ä‘iá»ƒm tÃ­n dá»¥ng Ä‘a chiá»u** káº¿t há»£p 3 nguá»“n dá»¯ liá»‡u:

1. ğŸ’° **Traditional Data**: ThÃ´ng tin tÃ i chÃ­nh (thu nháº­p, tiáº¿t kiá»‡m, ná»£)
2. ğŸ’³ **Transaction Data**: Lá»‹ch sá»­ giao dá»‹ch ngÃ¢n hÃ ng
3. ğŸ‘¥ **Social Data**: HÃ nh vi máº¡ng xÃ£ há»™i

### Káº¿t quáº£
- âœ… Dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n vá»›i **3 models ML** cháº¡y song song
- âœ… Tá»± Ä‘á»™ng phÃ¢n loáº¡i FICO score groups  
- âœ… API thá»i gian thá»±c cho á»©ng dá»¥ng ngÃ¢n hÃ ng
- âœ… Dashboard trá»±c quan cho quáº£n lÃ½

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Tá»•ng Quan

```
DATA PIPELINE
=============

1ï¸âƒ£ DATA COLLECTION
   CSV Upload â†’ S3 Raw Bucket

2ï¸âƒ£ DATA PROCESSING (AWS Glue ETL)
   S3 Raw â†’ Glue Jobs â†’ S3 Cleaned

3ï¸âƒ£ MODEL TRAINING (SageMaker)
   S3 Cleaned â†’ SageMaker Training Jobs
   â”œâ”€â”€ XGBoost Model (khÃ¡ch hÃ ng má»›i)
   â”œâ”€â”€ Traditional Model (PyTorch DNN)  
   â”œâ”€â”€ Social Model (Sklearn ExtraTrees)
   â””â”€â”€ Summary Model (Aggregate traditional + social)
   
   â†’ S3 Models Bucket

4ï¸âƒ£ INFERENCE API (Flask on EC2)
   Flask API Server (EC2 t3.medium)
   â€¢ New Customer â†’ XGBoost Model
   â€¢ Existing Customer â†’ Traditional + Social â†’ Summary Model
   
   Load Models from S3 â†’ Cache in Memory
   Query/Update Customer Data â†’ DynamoDB
   
   Response: Credit Score + FICO Group
```

---

## ğŸ“‹ Workflow Chi Tiáº¿t

### Scenario 1: KhÃ¡ch HÃ ng Má»›i
```
POST /api/v1/predict-new-customer
{
  "national_id": "001234567890",
  "income": 50000000,
  "savings": 10000000,
  "debt": 5000000,
  ...
}

Flask API:
1. Check DynamoDB â†’ Customer chÆ°a tá»“n táº¡i
2. Extract 10 features tá»« form
3. Load XGBoost model tá»« S3
4. Predict â†’ Score: 720
5. Map to FICO Group â†’ "Good"
6. Save vÃ o DynamoDB
7. Return response
```

### Scenario 2: KhÃ¡ch HÃ ng Hiá»‡n Há»¯u
```
POST /api/v1/predict-existing-customer
{
  "national_id": "001234567890"
}

Flask API:
1. Query DynamoDB â†’ Láº¥y toÃ n bá»™ data
2. Extract traditional_features
3. Extract social_features
4. Load Traditional model (PyTorch) â†’ Score A
5. Load Social model (Sklearn) â†’ Score B
6. Load Summary model â†’ Aggregate (A, B) â†’ Final Score
7. Update DynamoDB
8. Return response

Flow: Traditional + Social â†’ Summary Model â†’ Final Score
```

---

## Tech Stack

### Infrastructure
- AWS VPC: Network isolation
- EC2: Flask API server (t3.medium)
- S3: Data lake (raw, cleaned, models)
- DynamoDB: Customer database
- IAM: Role-based access

### ML/AI
- AWS Glue: ETL jobs
- SageMaker: Model training
- XGBoost: Gradient boosting
- PyTorch: Deep learning
- Sklearn: Random Forest

### API Layer
- Flask: RESTful API
- Gunicorn: WSGI server
- boto3: AWS SDK

---

## Quick Start

### 1. Prerequisites
```bash
- AWS Account
- Terraform >= 1.0
- AWS CLI configured
- Python 3.9+
```

### 2. Configure terraform.tfvars
```hcl
aws_profile          = "vpbank"
aws_region           = "ap-southeast-1"
environment          = "dev"
project_name         = "vpbank-ai-credit-score"
enable_flask_ec2     = true
flask_instance_type  = "t3.medium"
```

### 3. Deploy
```bash
terraform init
terraform plan
terraform apply
```

### 4. Test API
```bash
FLASK_IP=$(terraform output -raw flask_api_public_ip)

curl http://$FLASK_IP:5000/health

curl -X POST http://$FLASK_IP:5000/api/v1/predict-new-customer \
  -H "Content-Type: application/json" \
  -d '{
    "national_id": "001234567890",
    "income": 50000000,
    "savings": 10000000,
    "debt": 5000000,
    ...
  }'
```

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ main.tf                       # VPC, networking
â”œâ”€â”€ compute.tf                    # EC2, security groups
â”œâ”€â”€ s3.tf                         # S3 buckets
â”œâ”€â”€ dynamodb.tf                   # DynamoDB table
â”œâ”€â”€ glue.tf                       # Glue ETL jobs
â”œâ”€â”€ sagemaker.tf                  # SageMaker training
â”‚
â”œâ”€â”€ flask-app/                    # Flask API
â”‚   â”œâ”€â”€ app.py                    # Main app
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ API_GUIDE.md              # Full API docs
â”‚   â””â”€â”€ test_api.http
â”‚
â”œâ”€â”€ glue-scripts/                 # ETL scripts
â”œâ”€â”€ train_xgboost.py              # XGBoost training
â”œâ”€â”€ train_traditional_pytorch.py  # PyTorch training
â””â”€â”€ train_social.py               # Sklearn training
```

---

## ğŸ’° Cost Optimization

### Development (~$30/month)
```hcl
enable_nat_gateway = false
flask_instance_type = "t3.small"
```

### Production (~$200/month)
```hcl
enable_nat_gateway = true
flask_instance_type = "t3.medium"
# + Auto Scaling
# + Load Balancer
```

### Savings vs Old Architecture
```
Old (API Gateway + SageMaker Endpoints): $201/month
New (Flask on EC2): $36/month
SAVINGS: 82%
```

---

## ğŸ“š Documentation

- **API Guide**: `flask-app/API_GUIDE.md`
- **Architecture**: `flask-app/ARCHITECTURE.md`
- **Migration**: `INFRASTRUCTURE_CHANGES.md`
- **Tests**: `flask-app/test_api.http`

---

## ğŸ“Š Monitoring

```bash
# Flask logs
sudo journalctl -u flask-app -f

# Glue logs
aws logs tail /aws-glue/jobs/output --follow

# Lambda logs
aws logs tail /aws/lambda/glue-starter --follow
```

---

## ğŸ§¹ Cleanup

```bash
terraform destroy

# Empty S3 buckets first
aws s3 rm s3://vpbank-ai-credit-score-dev-raw --recursive
aws s3 rm s3://vpbank-ai-credit-score-dev-models --recursive
```

---

## ğŸ—ºï¸ Roadmap

### Phase 1: MVP (HoÃ n thÃ nh âœ…)
- [x] Infrastructure setup
- [x] 3 ML models pipeline
- [x] Flask API
- [x] DynamoDB storage

### Phase 2: Production (Äang triá»ƒn khai ğŸš§)
- [ ] HTTPS/SSL
- [ ] Auto Scaling
- [ ] Load Balancer
- [ ] CI/CD pipeline

### Phase 3: Advanced (Dá»± kiáº¿n ğŸ“…)
- [ ] Real-time streaming
- [ ] A/B testing
- [ ] Auto retraining
- [ ] Fraud detection

---

**Made with â¤ï¸ for VPBank Hackathon 2025**

VPBank AI Team
